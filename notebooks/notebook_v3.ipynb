{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5238fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b10e81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cus_class</th>\n",
       "      <th>quarter_idx</th>\n",
       "      <th>context_data_from</th>\n",
       "      <th>context_data_to</th>\n",
       "      <th>quarter</th>\n",
       "      <th>inflation</th>\n",
       "      <th>key_rate</th>\n",
       "      <th>deposit_1</th>\n",
       "      <th>deposit_3</th>\n",
       "      <th>deposit_6</th>\n",
       "      <th>deposit_12</th>\n",
       "      <th>fa_delta</th>\n",
       "      <th>usd_delta</th>\n",
       "      <th>IMOEX_delta</th>\n",
       "      <th>RGBI_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.14</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.14</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.14</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.14</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.14</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.86</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  cus_class  quarter_idx context_data_from context_data_to  \\\n",
       "0 2016-07-01      105.0            0        2016-07-01      2016-09-30   \n",
       "1 2016-07-01        1.0            0        2016-07-01      2016-09-30   \n",
       "2 2016-07-01      103.0            0        2016-07-01      2016-09-30   \n",
       "3 2016-07-01      106.0            0        2016-07-01      2016-09-30   \n",
       "4 2016-07-01      106.0            0        2016-07-01      2016-09-30   \n",
       "\n",
       "   quarter  inflation  key_rate  deposit_1  deposit_3  deposit_6  deposit_12  \\\n",
       "0        3       7.34      10.5       6.14       7.05       6.86        8.17   \n",
       "1        3       7.34      10.5       6.14       7.05       6.86        8.17   \n",
       "2        3       7.34      10.5       6.14       7.05       6.86        8.17   \n",
       "3        3       7.34      10.5       6.14       7.05       6.86        8.17   \n",
       "4        3       7.34      10.5       6.14       7.05       6.86        8.17   \n",
       "\n",
       "   fa_delta  usd_delta  IMOEX_delta  RGBI_delta  \n",
       "0      1.52       -5.3         1.85        2.48  \n",
       "1      1.52       -5.3         1.85        2.48  \n",
       "2      1.52       -5.3         1.85        2.48  \n",
       "3      1.52       -5.3         1.85        2.48  \n",
       "4      1.52       -5.3         1.85        2.48  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.utils import merge_frames\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "context = pd.read_csv(\"../data/context_df.csv\")\n",
    "pq = pd.read_parquet(\"../data/test_task.parquet\")\n",
    "percent_columns = [\n",
    "\t\"inflation\", \"key_rate\", \"deposit_1\", \"deposit_3\", \"deposit_6\", \"deposit_12\",\n",
    "\t\"fa_delta\", \"usd_delta\", \"IMOEX_delta\", \"RGBI_delta\"\n",
    "    ]\n",
    "df = merge_frames(pq, context)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bddc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df.copy()\n",
    "\n",
    "# –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "df_fe[\"year\"] = df_fe[\"date\"].dt.year\n",
    "df_fe[\"month\"] = df_fe[\"date\"].dt.month\n",
    "df_fe[\"quarter\"] = df_fe[\"date\"].dt.quarter\n",
    "\n",
    "# Feature engineering\n",
    "df_fe[\"deposit_spread\"] = df_fe[\"deposit_12\"] - df_fe[\"deposit_1\"]\n",
    "df_fe[\"usd_inverted\"] = -df_fe[\"usd_delta\"]\n",
    "df_fe[\"fa_vs_usd\"] = df_fe[\"fa_delta\"] - df_fe[\"usd_delta\"]\n",
    "\n",
    "# –ö–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–ª—è—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã\n",
    "df_fe = df_fe.sort_values(by=[\"quarter_idx\", \"date\"])\n",
    "df_fe[\"diff_inflation\"] = df_fe.groupby(\"quarter_idx\")[\"inflation\"].diff().fillna(0)\n",
    "\n",
    "base_percent_columns = [\n",
    "    \"inflation\", \"key_rate\", \"deposit_1\", \"deposit_3\", \"deposit_6\", \"deposit_12\",\n",
    "    \"fa_delta\", \"usd_delta\", \"IMOEX_delta\", \"RGBI_delta\"\n",
    "]\n",
    "engineered_columns = [\n",
    "    \"deposit_spread\", \"usd_inverted\", \"fa_vs_usd\", \"diff_inflation\",\n",
    "    \"year\", \"month\", \"quarter\"\n",
    "]\n",
    "final_columns = base_percent_columns + engineered_columns\n",
    "\n",
    "\n",
    "X = df_fe[final_columns].values\n",
    "y = df_fe[\"cus_class\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8df5e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_encoded), y=y_encoded)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1135eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_val_idx = next(splitter.split(X, df_fe[\"quarter\"]))\n",
    "\n",
    "X_train, y_train = X[train_idx], y_encoded[train_idx]\n",
    "X_temp, y_temp = X[test_val_idx], y_encoded[test_val_idx]\n",
    "\n",
    "val_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(val_splitter.split(X_temp, df_fe.iloc[test_val_idx][\"quarter\"]))\n",
    "\n",
    "X_val, y_val = X_temp[val_idx], y_temp[val_idx]\n",
    "X_test, y_test = X_temp[test_idx], y_temp[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eb93a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junknewera/workspace/machine-learning/interviews/tests/test_galera/venv/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "weights_tensor = class_weights_tensor.to(device)\n",
    "\n",
    "model = TabNetClassifier(\n",
    "    n_d=64,\n",
    "    n_a=64,\n",
    "    n_steps=5,\n",
    "    gamma=1.5,\n",
    "    lambda_sparse=1e-4,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-3),\n",
    "    mask_type='sparsemax',\n",
    "    device_name=device,\n",
    "    verbose=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44fac487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/30 19:22:24 INFO mlflow.tracking.fluent: Experiment with name 'tabnet_sota_baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.22878 | val_0_accuracy: 0.04537 |  0:00:02s\n",
      "epoch 10 | loss: 2.24267 | val_0_accuracy: 0.20333 |  0:00:27s\n",
      "epoch 20 | loss: 2.1813  | val_0_accuracy: 0.28819 |  0:00:52s\n",
      "epoch 30 | loss: 2.14988 | val_0_accuracy: 0.33975 |  0:01:16s\n",
      "epoch 40 | loss: 2.13121 | val_0_accuracy: 0.28688 |  0:01:39s\n",
      "epoch 50 | loss: 2.14612 | val_0_accuracy: 0.26567 |  0:02:02s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_accuracy = 0.33975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junknewera/workspace/machine-learning/interviews/tests/test_galera/venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unruly-carp-664 at: http://localhost:5000/#/experiments/606614082137499270/runs/212b8c207eea4e31a430ef7bbd8be04f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/606614082137499270\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"tabnet_sota_baseline\")\n",
    "with mlflow.start_run():\n",
    "    model.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=[\"accuracy\"],\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(weight=weights_tensor),\n",
    "        max_epochs=200,\n",
    "        patience=20,\n",
    "        batch_size=128,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    f1_macro = f1_score(y_test, preds, average=\"macro\")\n",
    "    f1_micro = f1_score(y_test, preds, average=\"micro\")\n",
    "\n",
    "    input_example = torch.tensor(X_train[:5], dtype=torch.float32).to(device)\n",
    "    output_example = model.predict(input_example.cpu().numpy())\n",
    "\n",
    "    mlflow.log_metric(\"f1_macro\", f1_macro)\n",
    "    mlflow.log_metric(\"f1_micro\", f1_micro)\n",
    "    mlflow.log_param(\"model\", \"TabNet_baseline\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, name=\"TabNet_baseline\",\n",
    "        signature=infer_signature(X_train[:5], output_example),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abde7494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 macro: 0.18236020484335805\n",
      "Test F1 micro: 0.3171288743882545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.28      0.31       407\n",
      "           1       0.07      0.46      0.12        13\n",
      "           2       0.00      0.00      0.00       530\n",
      "           3       0.56      0.36      0.44       787\n",
      "           4       0.16      0.54      0.25        28\n",
      "           5       0.06      0.62      0.10        21\n",
      "           6       0.04      0.09      0.06        58\n",
      "           7       0.62      0.84      0.71       388\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00        51\n",
      "          10       0.08      0.12      0.10        91\n",
      "          11       0.38      0.44      0.41       177\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.31      0.47      0.38       114\n",
      "          14       0.26      0.11      0.15       278\n",
      "          15       0.09      0.27      0.14        45\n",
      "          16       0.06      0.69      0.11        32\n",
      "          17       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.32      3065\n",
      "   macro avg       0.17      0.29      0.18      3065\n",
      "weighted avg       0.33      0.32      0.31      3065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"Test F1 macro:\", f1_macro)\n",
    "print(\"Test F1 micro:\", f1_micro)\n",
    "print(classification_report(y_test, preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aaae1056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at ../models/tabnet_baseline_model.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../models/tabnet_baseline_model.zip'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model(\"../models/tabnet_baseline_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04bfe3",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –±—É—Å—Ç–∏–Ω–≥–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb7cbebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 macro: 0.16129717652145248\n",
      "Test F1 micro: 0.4515497553017945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39       407\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.41      0.30      0.35       530\n",
      "           3       0.48      0.71      0.57       787\n",
      "           4       0.00      0.00      0.00        28\n",
      "           5       0.00      0.00      0.00        21\n",
      "           6       0.00      0.00      0.00        58\n",
      "           7       0.62      0.88      0.73       388\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00        51\n",
      "          10       0.50      0.01      0.02        91\n",
      "          11       0.43      0.42      0.42       177\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.28      0.61      0.38       114\n",
      "          14       0.24      0.03      0.05       278\n",
      "          15       0.00      0.00      0.00        45\n",
      "          16       0.00      0.00      0.00        32\n",
      "          17       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.45      3065\n",
      "   macro avg       0.18      0.19      0.16      3065\n",
      "weighted avg       0.39      0.45      0.39      3065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "model_c = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='MultiClass',\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "model_c.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_c.predict(X_test)\n",
    "\n",
    "print(\"Test F1 macro:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Test F1 micro:\", f1_score(y_test, y_pred, average=\"micro\"))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e612dfb",
   "metadata": {},
   "source": [
    "### –ú–æ–∂–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –±–æ–ª–µ–µ Lightweight –º–æ–¥–µ–ª—è–º–∏, —Ç–∞–∫–∂–µ –ø–æ–¥–æ–π—Ç–∏ –∫ –∑–∞–¥–∞—á–µ —Å –ø–æ–º–æ—â—å—é **arima, prophet, lstm, sequence-based nn** –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c44cbee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
